{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db29423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (1.106.1)\n",
      "Requirement already satisfied: deep_translator in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (1.11.4)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from openai) (2.11.7)\n",
      "Requirement already satisfied: sniffio in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from openai) (4.14.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from deep_translator) (4.13.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from deep_translator) (2.32.4)\n",
      "Requirement already satisfied: idna>=2.8 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep_translator) (2.8)\n",
      "Requirement already satisfied: certifi in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
      "Requirement already satisfied: httpcore==1.* in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dusty/.pyenv/versions/3.12.7/lib/python3.12/site-packages (from requests<3.0.0,>=2.23.0->deep_translator) (2.5.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai deep_translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e71d4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== СОБЕСЕДОВАНИЕ НАЧАТО ===\n",
      "HR: Привет, Алена, спасибо, что у меня есть. Я хотел бы начать с того, что немного рассказываю вам о себе. Я был с VTB в качестве менеджера по персоналу в течение последних трех лет, и я имею большой опыт работы в области приобретения талантов, отношений с сотрудниками и организационного развития. \n",
      "\n",
      "Что конкретно привлекает вас к работе здесь? Является ли это возможностью стать частью такого престижного банка, возможности профессионально расти или, возможно, поддерживающей рабочей средой?\n",
      "Кандидат: I have 18 years of IT experience, worked at EPAM and Retail.tech. I want to work at VTB because it's a stable bank with interesting challenges.\n",
      "--------------------------------------------------\n",
      "HR: Безусловно, спасибо, что поделились этим. В EPAM я управлял командой разработчиков, сосредоточившись на разработке программного обеспечения и управлении проектами. Как вы думаете, что сделал EPAM отличным местом для работы во время пребывания в должности?\n",
      "Кандидат: At EPAM I was Senior IT Infrastructure Support Engineer, managed 100+ workstations and 1000+ remote users.\n",
      "--------------------------------------------------\n",
      "HR: Отличные примеры моих навыков! В EPAM я имел дело с различными сложными задачами активного каталогов. Не могли бы вы уточнить конкретный сценарий, в котором вам приходилось устранить неполадок или реализовать что -то, что связано с Active Directory?\n",
      "Кандидат: Yes, I have experience with these technologies.\n",
      "--------------------------------------------------\n",
      "HR: Безусловно, виртуализация была также ключевой частью моей роли в EPAM. Я работал в первую очередь с VMware и Microsoft Hyper-V. Есть ли у вас какие -либо конкретные проекты виртуализации или проблемы с вашего времени в Retail.Tech, которые выделялись вам?\n",
      "Кандидат: Yes, I have experience with these technologies.\n",
      "--------------------------------------------------\n",
      "HR: Резолюция конфликта является решающим навыком для меня. В EPAM я нашел эффективное общение и активное слушание, чтобы быть ключевым при обращении к конфликтам команды. Не могли бы вы поделиться тем, когда вы успешно опосредовали конфликт между членами команды?\n",
      "Кандидат: Yes, I have experience with these technologies.\n",
      "--------------------------------------------------\n",
      "HR: Выбор VTB был для меня стратегическим решением. Это не только стабильный и уважаемый банк, но и возможность внести свой вклад в финансовое учреждение, которое ценит инновации, и развитие сотрудников резонирует с моими карьерными целями. Какие аспекты культуры или предложений VTB обращаются к вам больше всего?\n",
      "Кандидат: Yes, I have experience with these technologies.\n",
      "--------------------------------------------------\n",
      "\n",
      "=== ИТОГОВАЯ ОЦЕНКА ===\n",
      "Конечно, давайте проанализируем интервью:\n",
      "\n",
      "1. ** Технические навыки: ** Я бы оценил это как 4 из 5. Кандидат имеет солидный опыт в ИТ -инфраструктуре и опыте с ключевыми технологиями, такими как Active Directory и виртуализация.\n",
      "   \n",
      "2. ** Опыт Матч: ** Это оценивается в 5/5. Опыт кандидата прекрасно соответствует требованиям этой роли, особенно учитывая их предыдущие роли в EPAM и Retail.Tech.\n",
      "\n",
      "3.\n",
      "\n",
      "4. ** Общее впечатление: ** Это также сильный 5/5. Кандидат не только достиг, но и превзошел ожидания во всех обсуждаемых областях.\n",
      "\n",
      "5. Тем не менее, я также предложил бы провести интервью второго раунда, чтобы еще больше оценить их соответствие в нашей конкретной динамике команды.\n",
      "\n",
      "В целом, кандидат кажется сильным подходящим для роли в VTB.\n"
     ]
    }
   ],
   "source": [
    "from deep_translator import GoogleTranslator\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(base_url=\"http://localhost:1234/v1\", api_key=\"lm-studio\")\n",
    "\n",
    "# Список вопросов для собеседования\n",
    "interview_questions = [\n",
    "    \"Hi! I'm Alena, HR manager at VTB. Tell me about yourself and why you want to work here?\",\n",
    "    \"I see you have 18 years of experience. Tell me about your work at EPAM?\",\n",
    "    \"You mentioned Active Directory. What complex tasks did you solve with it?\",\n",
    "    \"Did you work with virtualization? What platforms?\",\n",
    "    \"How do you handle conflicts in a team?\",\n",
    "    \"Why did you choose VTB specifically?\"\n",
    "]\n",
    "\n",
    "# История разговора КОНТЕКСТ\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are HR manager Alena from VTB bank. Answer only with interview questions, one at a time.\"}\n",
    "]\n",
    "\n",
    "translator_to_ru = GoogleTranslator(target=\"ru\")\n",
    "translator_to_en = GoogleTranslator(source=\"ru\", target=\"en\")\n",
    "\n",
    "print(\"=== СОБЕСЕДОВАНИЕ НАЧАТО ===\")\n",
    "\n",
    "for i, question in enumerate(interview_questions):\n",
    "    # Задаем вопрос\n",
    "    messages.append({\"role\": \"user\", \"content\": question})\n",
    "    \n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"model-identifier\",\n",
    "        messages=messages,\n",
    "        temperature=0.7,\n",
    "        max_tokens=150\n",
    "    )\n",
    "    \n",
    "    # Переводим и выводим вопрос от HR\n",
    "    ai_question = completion.choices[0].message.content\n",
    "    print(f\"HR: {translator_to_ru.translate(ai_question)}\")\n",
    "    \n",
    "    # Добавляем в историю\n",
    "    messages.append({\"role\": \"assistant\", \"content\": ai_question})\n",
    "    \n",
    "    # Имитируем ответ кандидата (в реальной версии тут input())\n",
    "    if i == 0:\n",
    "        candidate_answer = \"I have 18 years of IT experience, worked at EPAM and Retail.tech. I want to work at VTB because it's a stable bank with interesting challenges.\"\n",
    "    elif i == 1:\n",
    "        candidate_answer = \"At EPAM I was Senior IT Infrastructure Support Engineer, managed 100+ workstations and 1000+ remote users.\"\n",
    "    else:\n",
    "        candidate_answer = \"Yes, I have experience with these technologies.\"\n",
    "    \n",
    "    print(f\"Кандидат: {candidate_answer}\")\n",
    "    messages.append({\"role\": \"user\", \"content\": candidate_answer})\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Финальная оценка\n",
    "evaluation_prompt = \"\"\"\n",
    "Analyze this interview. Rate candidate:\n",
    "1. Technical skills (1-5)\n",
    "2. Experience match (1-5)  \n",
    "3. Communication skills (1-5)\n",
    "4. Overall impression\n",
    "5. Recommendation: hire / interview again / reject\n",
    "\"\"\"\n",
    "\n",
    "messages.append({\"role\": \"user\", \"content\": evaluation_prompt})\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"model-identifier\",\n",
    "    messages=messages,\n",
    "    temperature=0.5,\n",
    "    max_tokens=300\n",
    ")\n",
    "\n",
    "print(\"\\n=== ИТОГОВАЯ ОЦЕНКА ===\")\n",
    "print(translator_to_ru.translate(completion.choices[0].message.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
